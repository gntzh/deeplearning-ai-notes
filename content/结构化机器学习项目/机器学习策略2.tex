\documentclass[../../main.tex]{subfiles}
\begin{document}
\chapter{机器学习策略2}

\section{进行误差分析}
% Carrying out error analysis
通过人工检查机器学习模型得出的结果中出现的一些错误，有助于深入了解下一步要进行的工作。这个过程被称作\textbf{错误分析（Error Analysis）}。

错误分析一方面是要找出错误来源，也是优化方向，另一方面还要判断优化上限，找到最有潜力的优化方向。比如对于猫图片识别器错误地将一些看上去像猫的狗误识别为猫，这时不应该立即去优化这个问题，应当去看看错误样本中狗占的比例，假如仅占5\%，那并不值得优化，因为即使解决了这个问题，性能不过提高了5\%（假如dev评估合理）；加入因为模糊图片而识别错误的比例占到60\%，那么显然这是个值得优化的问题。此外，在分析过程中，还可以将错误进一步细化，归纳出新的错误类型。

手动查看错误样本的方法虽然很累，但却十分必要，它不仅能够有效避免花费大量的时间与精力去做一些对提高模型性能收效甚微的工作，让我们专注于解决影响模型准确率的主要问题。

在具体实施时，可以在样本中随机选择一部分进行错误，分析，能够表现出问题即可；还可以使用电子表格等工具，加速分析过程，比如统计比例，做comment。

\section{清除标注错误的数据}
% Cleaning up Incorrectly labeled data
在错误分析过程中，可能会发现标注错误的数据（mislabeled examples），这时并不一定要立即修正，仍然要判断优化上限。

如果出现在训练集中，由于机器学习算法对于随机误差的稳健性（Robust，只要这些出错的样本数量较小，且分布近似随机，就不必花费时间一一修正。

如果出现在验证集和测试集中，则可以在进行误差分析时，通过统计人为标记错误所占的百分比，来大致分析这种情况对模型的识别准确率的影响，并比较该比例的大小和其他错误类型的比例，以此判断是否值得去将错误的标记一一进行修正，还是可以忽略。

如果要修正这些错误要保证：
\begin{itemize}
    \item 验证集和测试集同步修正，要保证它们来自相同的分布；
    \item 尽量同时检验算法判断正确和判断错误的样本；
    \item 训练集可以不同步修正，因为训练集的分布不必和验证/测试集完全相同，训练集的样本也太大。
\end{itemize}

\section{快速搭建你的第一个系统，并进行迭代}
% Build your first system quickly, then iterate

搭建一个新的机器学习系统时，要考虑的事情很对，但仍应快速确立验证/测试集和评估指标并搭建一个“quick and dirty”的初始系统，然后用它做偏差/方差分析，用它做错误分析，然后用分析结果确定下一步优先要做的方向，不断的迭代。

当然，更多的情况是有可借鉴的资料，那么可以从现有大量学术文献为基础出发。但如果是第一次处理某个新问题，不要想太多，先构建一个快速而粗糙的实现，它能帮你找到改善系统要优先处理的方向。

\section{使用来自不同分布的数据训练和测试}
% Training and testing on different distributions
有时，我们很难得到来自同一个分布的训练集和验证/测试集，比如我们可以通过爬虫获得很多来自网页的图片，却很少能得到来自实际场景中用户自己拍摄的图片，又或者可以买到大量通用的数据，但难以收集大量的该场景中的数据。

这时，不应该将少量的实际应用场景数据与其他数据打乱划分train/dev/test，而是保证验证/测试集都来自少量的实际应用场景数据，这时虽然训练集的分布虽然不同，但要由于其他方案。

\section{数据分布不匹配时，偏差与方差的分析}
% Bias and Variance with mismatched data distributions
之前的学习中，我们通过比较人类水平误差、训练集错误率、验证集错误率的相对差值来判断进行偏差/方差分析。但在训练集和验证/测试集分布不一致的情况下，无法根据相对差值来进行偏差/方差分析。这是因为训练集错误率和验证集错误率的差值可能来自于算法本身（归为方差），也可能来自于样本分布不同，和模型关系不大。

为了解决这个问题，我们可以再定义一个\textbf{训练-验证集（Training-dev Set）}。训练-验证集和训练集的分布相同（或者是训练集分割出的子集），但是不参与训练过程。
\begin{figure}[H]
    \centering
    \begin{tikzpicture}[>=Stealth,<->,font=\small]
    \node[right] (Bayes) at (0, 0) {Bayes error};
    \node[right] (Training) at (0, -2) {Training error};
    \node[right] (D-T) at (0, -4) {Development-Training error};
    \node[right] (Dev) at (0, -6) {Development set error};
    \node[right] (Test) at (0, -8) {Test set error};
    \draw (0.7, -0.3) -- ++(0, -1.4) node[midway, right] {Avoidable Bias};
    \draw (0.7, -2.3) -- ++(0, -1.4) node[midway, right] {Variance};
    \draw (0.7, -4.3) -- ++(0, -1.4) node[midway, right] {Data mismatch};
    \draw (0.7, -6.3) -- ++(0, -1.4) node[midway, right] {Degree of overfitting to the development set};
    \end{tikzpicture}
\end{figure}

\section{处理数据不匹配问题}
% Addressing data mismatch
这里有两条关于如何解决数据不匹配问题的建议：
\begin{enumerate}
    \item 做错误分析，尝试了解训练集和验证/测试集的具体差异（主要是人工查看训练集和验证集的样本）；
    \item 尝试将训练数据调整得更像验证集，或者收集更多类似于验证/测试集的数据。
\end{enumerate}

如果你打算将训练数据调整得更像验证集，可以使用的一种技术是人工合成数据。我们以语音识别问题为例，实际应用场合（验证/测试集）是包含背景噪声的，而作为训练样本的音频很可能是清晰而没有背景噪声的。为了让训练集与验证/测试集分布一致，我们可以给训练集人工添加背景噪声，合成类似实际场景的声音。

人工合成数据能够使数据集匹配，从而提升模型的效果。但需要注意的是，不能给每段语音都增加同一段背景噪声，因为这样模型会对这段背景噪音出现过拟合现象，使得效果不佳。

\section{迁移学习}
% Transfer learning
\textbf{迁移学习（Tranfer Learning）}是通过将已训练好的神经网络模型的一部分网络结构应用到另一模型，将一个神经网络从某个任务中学到的知识和经验运用到另一个任务中，以显著提高学习任务的性能。

如果新的数据集很小，可能只需要重新训练输出层前的最后一层的权重，即\(W^{[L]}\)、\(b^{[L]}\)，并保持其他参数不变；而如果有足够多的数据，可以只保留网络结构，重新训练神经网络中所有层的系数,这时初始权重由之前的模型训练得到。这个过程称为\textbf{预训练（Pre-Training）}，之后的权重更新过程称为\textbf{微调（Fine-Tuning）}。

当然，不止可以加入一个新的输出层，还可以向神经网络加几个新层。
在下述场合进行迁移学习是有意义的：
\begin{itemize}
    \item 两个任务有同样的输入（比如都是图像或者都是音频）；
    \item 拥有更多数据的任务迁移到数据较少的任务；
    \item 某一任务的低层次特征（底层神经网络的某些功能）对另一个任务的学习有帮助。
\end{itemize}

\section{多任务学习}
% Multi-task learning
迁移学习中的步骤是串行的；而\textbf{多任务学习（Multi-Task Learning）}使用单个神经网络模型，利用共享表示采用并行训练同时学习多个任务。多任务学习的基本假设是多个任务之间具有相关性，并且任务之间可以利用相关性相互促进。

以汽车自动驾驶为例，需要实现的多任务是识别行人、车辆、交通标志和信号灯。如果在输入的图像中检测出车辆和交通标志，则输出的 y 为：\[y=\begin{bmatrix}
        0 \\1\\1\\0
    \end{bmatrix}\]
代价函数也就变成了：
\[J=\frac{1}{m} \sum^m_{i=1} \sum^c_{j=1} L(\hat y_j^{(i)}, y_j^{(i)})\]
其中，j 代表任务下标，总有 c 个任务。对应的损失函数为：
\[L(\hat y_j^{(i)}, y_j^{(i)}) = -y_j^{(i)} \log \hat y_j^{(i)} - (1 -y_j^{(i)})\log(1 - \hat y_j^{(i)})\]
多任务学习和 Softmax 回归看上去有些类似，容易混淆。它们的区别是，Softmax 回归的输出向量 y 中只有一个元素为 1（one-hot）；而多任务学习的输出向量 y 中可以有多个元素为 1。

多任务学习也可以处理图像只有部分物体被标记的情况，计算\(J\)时\(j\)仅求和有标签的值即可。

在下述场合进行多任务学习是有意义的：
\begin{itemize}
    \item 训练的一组任务可以共用低层次特征；
    \item \textbf{通常}，每个任务的数据量接近；\\如果其他任务的数据量远多余某一任务，则会显著增强该任务的学习；如果数据量具有对称性，也许能增强每一个任务。
    \item 能够训练一个足够大的神经网络，以同时做好所有的工作。\\多任务学习会降低性能的唯一情况（即和为每个任务训练单个神经网络相比性能更低的情况）是神经网络还不够大。
\end{itemize}

在多任务深度网络中，低层次信息的共享有助于减少计算量，同时共享表示层可以使得几个有共性的任务更好的结合相关性信息，任务特定层则可以单独建模任务特定的信息，实现共享信息和任务特定信息的统一。

在实践中，多任务学习的使用频率要远低于迁移学习，计算机视觉领域中的物体检测任务使用较多。

\section{什么是端到端的深度学习？}
% What is end-to-end deep learning?
在传统的机器学习分块模型中，每一个模块处理一种输入，然后其输出作为下一个模块的输入，构成一条流水线（pipeline）。而\textbf{端到端深度学习（End-to-end Deep Learning）}只用一个单一的神经网络模型来实现所有的功能。它将所有模块混合在一起，只关心输入和输出。

端到端学习依赖大量的数据，即使是很复杂的映射，数据量足够大，神经网络复兴足够复杂，神经网络也能挖掘出来。如果数据量较少，在传统机器学习分块模型所构成的流水线效果会很不错。

典型的例子就是\textit{机器翻译}，传统的机器学习会提取各种特征，最后才会得到翻译文本，而现在能够收集大量的数据，这时精心设计的组件反而没有端到端学习的表现好。

另一个反例则是人脸验证，如果使用端到端学习，实际应用时用户角度、距离不同，难以收集到大量的数据，而如果划分成两个子模块：寻找人脸和人脸对比，问题可以得到更好的解决，因为寻找人脸的数据使用任意的人脸即可，有大量的数据，人脸对比的数据通过不同组合也会有很多。

\section{是否要使用端到端的深度学习？}
% Whether to use end-to-end learning?
\noindent 端到端学习的优点：
\begin{itemize}
    \item 只要有足够多的数据，剩下的全部交给一个足够大的神经网络；\\比起传统的机器学习分块模型，可能更能捕获数据中的任何统计信息，而不需要用人类固有的认知（或者说，成见）来进行分析；
    \item 所需手工设计的组件更少，简化设计工作流程。
\end{itemize}
缺点：
\begin{itemize}
    \item 需要大量的数据；
    \item 需要复杂的模型；\\也许现有的算力，无法支持如此复杂的映射。
    \item 排除了可能有用的人工设计组件。
\end{itemize}

从知识的角度而言，\textit{算法的获取知识的主要来源是数据和人手工设计的任何东西}。当有大量数据时，手工设计的东西就不太重要了，但是当没有太多的数据时，构造一个精心设计的系统，实际上可以将人类对这个问题的很多认识直接注入到问题里，进入算法里应该挺有帮助的。

总而言之，手工设计组件的好处主要在于注入人类的知识，同时还可能影响训练数据库获得的难易，而坏处在于人类的知识也许并不有效，也许丢失了一些知识，而交给模型去从大数据中学习知识会更好。

\end{document}