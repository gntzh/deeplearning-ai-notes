\documentclass[../../main.tex]{subfiles}
\begin{document}
\chapter{神经网络的编程基础}
% Basics of Neural Network programming
\section{二分类}
% Binary Classification

\section{逻辑回归}
% Logistic Regression

\section{逻辑回归的代价函数}
% Logistic Regression Cost Function

\section{梯度下降法}
% Gradient Descent

\section{导数}
% Derivatives

\section{更多的导数例子}
% More Derivative Examples

\section{计算图}
% Computation Graph

\section{使用计算图求导数}
% Derivatives with a Computation Graph
% 链式求导法则 chain rule

\section{逻辑回归中的梯度下降}
% Logistic Regression Gradient Descent

\section{m 个样本的梯度下降}
% Gradient Descent on m Examples

\section{向量化}
% Vectorization

\section{向量化的更多例子}
% More Examples of Vectorization

\section{向量化逻辑回归}
% Vectorizing Logistic Regression

\section{向量化 logistic 回归的梯度输出}
% Vectorizing Logistic Regression's Gradient

\section{Python 中的广播}
% Broadcasting in Python

\section{关于NumPy中向量的说明}
% A note on python or numpy vectors

\section{Jupyter/iPython Notebooks快速入门}
% Quick tour of Jupyter/iPython Notebooks

\section{logistic 损失函数的解释}
% Explanation of logistic regression cost function

\end{document}