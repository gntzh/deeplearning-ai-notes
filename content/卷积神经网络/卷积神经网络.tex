\documentclass[../../main.tex]{subfiles}
\begin{document}
\chapter{卷积神经网络基础}
% Foundations of Convolutional Neural Networks

\section{计算机视觉}
% Computer vision
\textbf{计算机视觉（Computer Vision）}是个十分重要的领域，又很多算法和结构应用在其他领域。典型的计算机视觉问题有
\begin{itemize}
    \item 图片分类（Image Classification）
    \item 目标检测（Object detection）
    \item 图片风格迁移（Neural Style Transfer）
\end{itemize}

但在应用计算机视觉时要面临一个挑战，就是数据的输入可能会非常大。例如一张 1000×1000×3 的图片，神经网络输入层的维度将高达三百万，如果第一个隐藏层有1000个隐藏单元，若使用标准的全连接，那么\(W^{[1]}\)就将有30亿个参数。这样会有两个严重的问题：
\begin{enumerate}
    \item 在参数如此大量的情况下，难以获得足够的数据来防止神经网络发生过拟合和竞争需求；
    \item 所需内存和计算量巨大。
\end{enumerate}
因此，一般的神经网络很难处理蕴含着大量数据的图像。解决这一问题的方法就是使用\textbf{卷积神经网络（Convolutional Neural Network, CNN）}。

\section{边缘检测示例}
% Edge detection example
以\textbf{边缘检测（Edge detection）}中最简单的垂直边缘检测为例，来解释卷积操作。我们对一个\(6×6\)的灰度图像做垂直边缘检测，需要一个\textbf{过滤器（filter）}或\textbf{核（kernel）}：
\[
    \begin{bmatrix}
        3 & 0 & 1 & 2 & 7 & 4 \\
        1 & 5 & 8 & 9 & 3 & 1 \\
        2 & 7 & 2 & 5 & 1 & 3 \\
        0 & 1 & 3 & 1 & 7 & 8 \\
        4 & 2 & 1 & 6 & 2 & 8 \\
        2 & 4 & 5 & 6 & 2 & 8 \\
    \end{bmatrix}
    *
    \begin{bmatrix}
        1 & 0 & -1 \\
        1 & 0 & -1 \\
        1 & 0 & -1 \\
    \end{bmatrix}
    =
    \begin{bmatrix}
        -5  & -4 & 0  & 8   \\
        -10 & -2 & 2  & 3   \\
        0   & -1 & -4 & -7  \\
        -3  & -2 & -3 & -16 \\
    \end{bmatrix}
\]
计算步骤：
filter 从左上开始，与同形状区域的矩阵做元素乘法（element-wise products）并求和，作为结果矩阵的第1行第1列元素；filter右移一步，得第1行第2列元素，类似的下移则得第2行第1列元素；如此平移得出结果矩阵。

若设输入形状为\(n×n\)，filter形状为\(f×f\)，易知结果矩阵形状为\((n-f+1)×(n-f+1)\)。
% TODO 添加垂直/水平边缘检测可视化例子

\section{更多边缘检测内容}
% More edge detection
过滤器取\(
\begin{bmatrix}
    1  & 1  & 1  \\
    0  & 0  & 0  \\
    -1 & -1 & -1 \\
\end{bmatrix}
\)，即可实现水平边缘检测。

常见得过滤器还有：\textbf{Sobel filter}，它的优点在于增加了中间一行元素的权重，这使得结果的鲁棒性会更高一些；
\[
    \begin{bmatrix}
        1 & 0 & -1 \\
        2 & 0 & -2 \\
        1 & 0 & -1 \\
    \end{bmatrix}
\]
还有\textbf{Scharr filter}。
\[
    \begin{bmatrix}
        3  & 0 & -3  \\
        10 & 0 & -10 \\
        3  & 0 & -3  \\
    \end{bmatrix}
\]

但我们不用去手写合适得过滤器，我们可以将过滤器设为参数，通过数据反馈，让神经网络自动去学习它们，这样得出得过滤器可以检测出45°或70°或73°，甚至是任何角度的边缘，对于数据的捕捉能力甚至可以胜过任何之前这些手写的过滤器。

\section{Padding}
卷积操作有两个问题：
\begin{itemize}
    \item 每次卷积操作后，输出的形状缩小。
    \item 边缘区参与操作较少，丢失边缘位置的很多信息。
\end{itemize}
了解决这些问题，可以在进行卷积操作前，对原始图片在边界上进行\textbf{填充（Padding）}，以增加矩阵的大小。通常将 0 作为填充值。

若在周围填充\(p\)个像素，则输入形状为\(n+2p\)，输出形状也就变成了\((n+2p-f+1) × (n+2p-f+1)\)。

根据填充不同，进行卷积运算时，常用的有两种选择：
\begin{itemize}
    \item \textbf{Valid 卷积}：不填充，直接卷积，输出形状为\((n-f+1)×(n-f+1)\)；
    \item \textbf{Same 卷积}：填充并使得输出形状与输入一致，则\(p = \frac{f-1}{2}\)。
\end{itemize}
注意，\(f\)通常取奇数，这样Same 卷积的\(p = \frac{f-1}{2}\)可以得到整数以进行对称填充，并且过滤器有一个便于表示其所在位置的中心点。

\section{卷积步长}
% Strided convolutions
卷积过程中，有时需要通过填充来避免信息损失，有时也需要通过设置过滤器移动的\(步长 Stride\)来压缩一部分信息。若设为步长为\(s\)，则输出的形状为：
\[\biggl\lfloor \frac{n+2p-f}{s}+1   \biggr\rfloor \times \biggl\lfloor \frac{n+2p-f}{s}+1 \biggr\rfloor\]
注意，公式中有一个向下取整的符号，这是一个惯例：过滤器必须完全处于图像中或者填充之后的图像区域内才输出相应结果。

另外，需要注意的是，前文中都称这种运算为卷积操作，而非卷积运算，真正的卷积运算在做元素乘积求和之前，要将过滤器先顺时针旋转\(90°\)。
数学上的卷积满足结合律\((A*B)*C = A*(B*C) \)，这对于一些信号处理应用来说很有用，但对神经网络并不重要，所以我们跳过了镜像操作，其实我们做的“卷积”被称为\textbf{互相关（cross-correlation）}而不是数学意义上的卷积（convolution）。

\section{三维卷积}
% Convolutions over volumes
三维卷积的过滤器也是三维的，不过输出矩阵是二维的，仍然是过滤器和同形状区域做元素乘法然后求和，得到输出中的一个元素。
\begin{figure}[H]
    \centering
    \begin{tikzpicture}[on grid]
        \node at (30mm, -12mm) {\(*\)};
        \foreach \x[count=\i from 0] in {blue!60, green!60, red!60}{
            \fill[color=\x,xshift=-2mm*\i,yshift=-2mm*\i] (0, 0) rectangle (24mm, -24mm);
            \draw[step=4mm,xshift=-2mm*\i,yshift=-2mm*\i] (0, 0) grid (24mm, -24mm);
            
            \fill[color=yellow,fill opacity=0.65,xshift=-2mm*\i, yshift=-2mm*\i] (0, 0) rectangle (12mm, -12mm);
            \draw[step=4mm,xshift=-2mm*\i, yshift=-2mm*\i] (0,0) grid (12mm, -12mm);

            \fill[color=yellow,xshift={-2mm*\i +40mm},yshift={-2mm*\i -4mm}] (0, 0) rectangle (12mm, -12mm);
            \draw[step=4mm,xshift={-2mm*\i +40mm},yshift={-2mm*\i -4mm}] (0,0) grid (12mm, -12mm);
        }
        \node at (58mm, -12mm) {\(=\)};
        \fill[color=cyan,xshift=58mm+6mm,yshift=-12mm+8mm] (0, 0) rectangle (16mm, -16mm);
        \draw[step=4mm,xshift=58mm+6mm,yshift=-12mm+8mm] (0,0) grid (16mm, -16mm);
    \end{tikzpicture}
\end{figure}
这样就是进行了一个边缘检测，如果想要更多边缘检测，就使用更多的过滤器与输入矩阵作卷积操作，如果使用了6个过滤器，那么就有了6个二维的输出，堆叠在一起相当于一个三维输出。

第三维度（的大小）称为\textbf{通道（channels）}或\textbf{深度（depth）}，那么过滤器的通道数必须和输入一致，输出的通道数由过滤器数量决定。同时高和宽并不要求相等，那么就用\(n_H×n_W×n_C\)来表示三维矩阵的形状。

\section{单层卷积网络}
% One layer of a convolutional network
一个单层卷积网络：
\begin{enumerate}
    \item 输入和各过滤器作卷积操作；
    \item 各输出各自偏置；
    \item 激活函数；
    \item 堆叠各输出得到三维输出。
\end{enumerate}
符号表示：
\begin{itemize}
    \item \(f^{[l]}\)：第\(l\)层过滤器高（宽）
    \item \(p^{[l]}\)：第\(l\)层填充长度
    \item \(s^{[l]}\)：第\(l\)层步长
    \item \(n^{[l]}_C\)：第\(l\)层过滤器的数量
\end{itemize}
在此基础上，
\begin{itemize}
    \item 输入形状：\(n_H^{[l-1]} × n_W^{[l-1]} × n_C^{[l-1]}\)
    \item 输出形状：\(n_H^{[l]} × n_W^{[l]} × n_C^{[l]}\)，其中：
    \begin{align*}
         & n^{[l]}_H = \biggl\lfloor \frac{n^{[l-1]}_H+2p^{[l]}-f^{[l]}}{s^{[l]}}+1   \biggr\rfloor \\
         & n^{[l]}_W = \biggl\lfloor \frac{n^{[l-1]}_W+2p^{[l]}-f^{[l]}}{s^{[l]}}+1   \biggr\rfloor
    \end{align*}
    \item 过滤器形状：\(f^{[l]} × f^{[l]} × n_C^{[l-1]}\)
    \item 权重维度：\(f^{[l]} × f^{[l]} × n_C^{[l-1]} × n_C^{[l]}\)
    \item 偏置尺寸：\(n_C^{[l]}\)
\end{itemize}

\section{简单卷积网络示例}
% A simple convolution network example
一个简单的卷积神经网络：
\begin{enumerate}
    \item 输入
    \item 多个卷积层（Convolution layer）
    \item 多个全连接层（Fully Connected layer）
    \item 最后 Softmax
\end{enumerate}
随着神经网络计算深度不断加深，\(n_H^{[l]}\)、\( n_W^{[l]}\)般逐渐减小，，\(n_C^{[l]}\)逐渐增加。

一个典型的卷积神经网络通常包含有三种层：\textbf{卷积层（Convolution layer）}、\textbf{池化层（Pooling layer）}、\textbf{全连接层（Fully Connected layer）}。

\section{池化层}
% Pooling layers
\index{Pooling layer@Pooling layer 池化层}
池化层的作用是缩减模型的大小，提高计算速度，同时减小噪声，提高所提取特征的鲁棒性。
\index{Pooling layer@Pooling layer 池化层!Max Pooling 最大池化}
采用较多的一种池化过程叫做\textbf{最大池化（Max Pooling）}。池化过程类似于卷积过程，不同的是取该区域的最大值，而不是乘积求和，而且池化的不同通道分别计算。若池化的超参数\(f=2, s=2\)，那么池化的输出相比输入高度、宽度减小一半。

对最大池化的一种直观解释是，元素值较大可能意味着池化过程之前的卷积过程提取到了某些特定的特征，池化过程中的最大化操作使得只要在一个区域内提取到某个特征，它都会保留在最大池化的输出中。但是，没有足够的证据证明这种直观解释的正确性，而最大池化被使用的主要原因是它在很多实验中的效果都很好。

\index{Pooling layer@Pooling layer 池化层!Average Pooling 最大池化}
另一种池化过程是平均池化（Average Pooling），就是从取某个区域的最大值改为求这个区域的平均值。

池化过程的超参数包括过滤器的大小\(f\)、步长\(s\)，以及选用最大池化还是平均池化。而填充\(p\)则很少用到。那么池化的输出形状为：\[
    \biggl\lfloor \frac{n_H-f}{s}+1   \biggr\rfloor \times \biggl\lfloor \frac{n_W-f}{s}+1   \biggr\rfloor \times n_c
\]

\section{卷积神经网络示例}
% Convolutional neural network example
一个识别数字的简单卷积神经网络：
\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|}
        \hline
                            & Activation shape & Activation Size & \# parameters \\ \hline
        Input               & (32, 32, 3)      & 3072            & 0            \\ \hline
        CONV1(\(f=5, s=1\)) & (28, 28 ,8)      & 6272            & 608          \\ \hline
        POOL1               & (14, 14, 8)      & 1568            & 0            \\ \hline
        CONV1(\(f=5, s=1\)) & (10, 10, 16)     & 1600            & 1216         \\ \hline
        POOL2               & (5, 5, 8)        & 400             & 0            \\ \hline
        FC3                 & (120, 1)         & 120             & 48001        \\ \hline
        FC4                 & (84, 1)          & 84              & 10081        \\ \hline
        Softmax             & (10, 1)          & 10              & 841          \\ \hline
    \end{tabular}
\end{table}
在计算神经网络的层数时，通常只统计具有权重和参数的层，因此池化层通常和之前的卷积层共同计为一层。

有几点要注意，第一，池化层和最大池化层没有参数；第二卷积层的参数相对较少，前面课上我们提到过，其实许多参数都存在于神经网络的全连接层。观察可发现，随着神经网络的加深，激活值尺寸会逐渐变小，如果激活值尺寸下降太快，也会影响神经网络性能。

\section{为什么使用卷积？}
% Why convolutions?
相比标准神经网络，对于大量的输入数据，卷积过程有效地减少了 CNN 的参数数量，原因有以下两点：
\index{parameter sharing@parameter sharing 参数共享}
\index{sparsity of connections@sparsity of connections 稀疏连接}
\begin{itemize}
    \item \textbf{参数共享（Parameter sharing）}：特征检测如垂直边缘检测如果适用于图片的某个区域，那么它也可能适用于图片的其他区域。不仅适用于边缘特征这样的低阶特征，同样适用于高阶特征。
    \item \textbf{稀疏连接（Sparsity of connections）}：在每一层中，由于过滤器的尺寸限制，输入和输出之间的连接是稀疏的，每个输出值只取决于输入在局部的一小部分值。
\end{itemize}

CNN可以通过这两种机制减少参数，以便我们用更小的训练集来训练它，从而预防过度拟合。并且 CNN 比较擅长捕捉区域位置偏移。即进行物体检测时，不太受物体在图片中位置的影响，增加检测的准确性和系统的鲁棒性。

\end{document}